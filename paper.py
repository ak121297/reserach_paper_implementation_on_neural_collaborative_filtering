# -*- coding: utf-8 -*-
"""paper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4MAlWWHCAB_0wR_IfxiBHIdwqXogCXr
"""

import keras
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
#warnings.filterwarnings('ignore')split
warnings.filterwarnings('ignore')

printf("implementation of research paper on collaborative filtering") 
# %matplotlib inline

dataset=pd.read_csv("ml-1m.train.csv",sep='\t',names="userid,itemid,ratings,timespace".split(','))
dataset.head()

#dataset2=pd.read_csv("ml-1m.test.csv",sep='\t',names="userid,itemid,ratings,timespace".split(','))
#dataset2.head()

from sklearn.model_selection import train_test_split
train,test=train_test_split(dataset,test_size=0.2,random_state=1)
dataset.userid = dataset.userid.astype('category').cat.codes.values
dataset.itemid = dataset.itemid.astype('category').cat.codes.values

from keras.layers import Input

from keras.layers import Embedding,Flatten,Dropout

no_users=len(dataset.userid.unique())

no_items=len(dataset.itemid.unique())
no_users
#ml=keras.layers.Input(shape=[1],name='ml')
#type(ml,no_ite)
#from keras.models import Sequential

#model = Sequential()

mlpu=Input(shape=[1],name='mlpu')
mlpu1=keras.layers.Embedding(no_users+1,10,name='mlpu_embed')(mlpu)
type(mlpu)

train.head()

test.head()

mlpu1=Flatten(name='mlpu_flatten')(mlpu1)
mlpu1=Dropout(0.2)(mlpu1)

mlpi=Input(shape=[1],name='mlpi')
mlpi2=Embedding(no_items+1,7,name='mlpi_embed')(mlpi)
mlpi2=Flatten(name='mlpi2_flatten')(mlpi2)
mlpi2=Dropout(0.2)(mlpi2)

#mlpu=Input(shape=[1],name='mlpu')
mfu=Embedding(no_users+1,8,name='mfu')(mlpu)
mfu=Flatten(name='mfu_flatten')(mfu)
mfu=Dropout(0.2)(mfu)

#mlpi=Input(shape=[1],name='mfi')
mfi=Embedding(no_items+2,8,name='mfi')(mlpi)
mfi=Flatten(name='mfi_flatten')(mfi)
mfi=Dropout(0.2)(mfi)

concatenate=keras.layers.concatenate([mlpu1,mlpi2],axis=-1)

dot=keras.layers.dot([mfu,mfi],axes=-1)

from keras.layers import BatchNormalization,Dense
concatenate = Dropout(0.2)(concatenate) 

con=Dense(200)(concatenate)
con=BatchNormalization()(con)

con=Dropout(0.2)(con)

con2=Dense(100)(con)
con2=BatchNormalization()(con2)
con2=Dropout(0.2)(con2)

con3=Dense(50)(con2)
con3=Dense(20)(con3)
con3=Dense(1)(con3)



mlp_mf=keras.layers.concatenate([con3,dot],axis=-1)

mlp_mf=Dense(100)(mlp_mf)
mlp_mf=Dense(100)(mlp_mf)
mlp_mf=Dense(1)(mlp_mf)

from keras import Model
model=Model([mlpu,mlpi],mlp_mf)

model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])

model.fit([train.userid,train.itemid],train.ratings, epochs=10,verbose=0,validation_split=0.15)

model.summary()

test.userid,test.itemid

#from sklearn.metrics import mean_absolute_error
y_true=test.ratings
y_hats =(np.round(model.predict([test.userid, test.itemid])))

print("model performance on test set")

scores = model.evaluate([train.userid, train.itemid], train.ratings, verbose=0)
#print(scores)
print("accuracy: %.2f%%" % (scores[0]*100))

from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
SVG(model_to_dot(model,  show_shapes=False, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))


